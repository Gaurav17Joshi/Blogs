---
layout: post
title: "GSoC - Week 1-2"
subtitle: "Work in Community Bonding"
date: 2023-06-14
background: '/img/posts/GSoC.png'
tags: gsoc
---

## The implementation
In the first two weeks I focussed on understanding the implementation of the project. In the source repository Celerite library was used for GP implimentation and Bilby was used for Bayesian Inferencing, while in my project my mentor and I decided to completely use a Jax based backend hense, Tinygp for GP, and Jaxns for Nested Sampling.

I made a proof of Concept implimentation for the QPO kernel and gaussian mean model for a lightcurve, which is explained in breif here:-

### Kernel:
For making the Kernel, I used Tingp.quasisep.celerite kernels which are a fast implementation (based on the celerite kernel) of the Qpo kernel.

$ k_{qpo+rn}(\tau) = k_{qpo}(\tau) + k_{rn}(\tau) $

$$  k_{qpo+rn}(\tau) = k_{qpo}(\tau) + k_{rn}(\tau)   $$

$$  k_{qpo+rn}(\tau) = a_{qpo} \exp(-c_{qpo} \tau) \cos(2\pi f \tau) + a_{rn} \exp(-c_{rn} \tau)  $$

```math
k_{qpo+rn}(\tau) = k_{qpo}(\tau) + k_{rn}(\tau)
```

The `quasisep.exp` kernel for the red noise part and the `quasisep.celerite` kernel for the qpo part can be implemented as:
```python
hqpokernel = kernels.quasisep.Exp(
    scale = 1/hqpoparams["crn"], sigma = (hqpoparams["arn"])**0.5) + kernels.quasisep.Celerite(
        a = hqpoparams["aqpo"], b = 0.0, c = hqpoparams["cqpo"], d = 2*jnp.pi*hqpoparams["freq"])
```

<img src="{{site.baseurl}}/img/assets/kernel1.png" alt="Plot of High, low and non QPO kernel">

### Mean:
We are working on Extremely powerful events in the universe which emit radiation in the Xray spectra. Many of these have some sort of flaring behaviour, and also in general, we wanted to add mean functions to our GPs as this feature will be extended to other astronomical time series.

For this proof of concept implimentation, I used a simple gaussian mean to test out sampling using Jaxns
Using the tinygp library to make the gaussian process and sample out some lightcurves from it.

```python
def gaussian(t, mean_params):
    return mean_params["A"] * jnp.exp(-((t - mean_params["t0"])**2)/(2*(mean_params["sig"]**2)))

mean_params = {
    "A" : 3,    "t0" : 0.5,    "sig" : 0.2,}

mean = functools.partial(gaussian, mean_params = mean_params)
# Making the Gp
gp = tinygp.GaussianProcess( kernel, t, mean=mean, diag = diag)
gp_sample   =  gp.sample( jax.random.PRNGKey(11), shape=(1,))
```

<img src="{{site.baseurl}}/img/assets/samples1.png" alt="Plot of samples">


## Jaxns and its use


## Tensor flow probability


## My adventure with the implimentation

